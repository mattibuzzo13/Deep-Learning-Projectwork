---

## Deep Learning 3D Reconstruction Notebook

This Jupyter Notebook implements a convolutional pipeline for 3D volumetric reconstruction. Given multiâ€‘view RGB inputs, it learns to predict a voxel grid representation of an object.

### ðŸš€ Project Goal
Train a deep neural network that, for each batch of input images shaped `[B, 3, H, W]`, outputs a volumetric occupancy grid. A composite loss (reconstruction + regularization) ensures accurate, smooth 3D shapes.

---

### ðŸ“‘ Notebook Sections

1. **Project Goal**  
   Highâ€‘level description of objectives and evaluation metrics.

2. **Dataset Acquisition and Preparation**  
   - Mount Google Drive (Colab)  
   - Download and cache multiâ€‘view RGB images and groundâ€‘truth voxel data  
   - Custom dataset class with onâ€‘theâ€‘fly transforms  

3. **Reconstruction Network**  
   - **Configuration Management** (`cfg` dict): hyperparameters & paths  
   - **Data Loading**: `VoxelDataset` plus caching logic  
   - **Model Architecture**: 3Dâ€‘conv decoder paired with 2Dâ€‘conv encoder  
   - **Loss Composition**: Binary crossâ€‘entropy, IoU, plus weight penalties  
   - **Visualization Helpers**: Live plots via Matplotlib & Plotly  
   - **Training Loop**: `train_model(cfg)` with mixed precision & TensorBoard  

4. **Experiment Entry Point**  
   Scriptâ€‘style launcher to swap configs, resume checkpoints, or run ablations.

5. **Inference & Final Results**  
   - Load best checkpoint  
   - Generate voxel predictions  
   - Render meshes with Trimesh & Plotly for interactive viewing  

---

### âš™ï¸ Prerequisites

- **Python** â‰¥ 3.8  
- **PyTorch** & **torchvision**  
- **NumPy**, **Pillow**  
- **trimesh**  
- **plotly**, **matplotlib**  
- **tensorboard**

Install via:
```bash
pip install torch torchvision numpy pillow trimesh plotly matplotlib tensorboard
```

---

### â–¶ï¸ Usage

1. **Clone & open** the notebook:
   ```bash
   git clone https://github.com/mattibuzzo13/Deep-Learning-Projectwork.git
   cd Deep-Learning-Projectwork
   jupyter notebook Projectwork_Deepl_Learning.ipynb
   ```
2. **Run cells in order**:
   - SectionsÂ 1â€“2: data setup  
   - SectionÂ 3: model definition & training  
   - SectionÂ 4: experiment runner  
   - SectionÂ 5: inference & visualization  

3. **Monitor** training metrics:
   ```bash
   tensorboard --logdir runs/
   ```

4. **Customize** by editing the topâ€‘cell `cfg` dictionary or passing flags in SectionÂ 4.

---

> **Tip:** For a fully persistent Colab workflow, mount your Google Drive at the start to store data and checkpoints seamlessly.
